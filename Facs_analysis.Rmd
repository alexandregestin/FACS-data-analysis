---
title: "R Notebook"
author: "A.Gestin"
output: html_notebook
---
Important note: it is currently designed to be applied on living cells only with compensated data (flowJo)
this workflow depends on packages: flowCore, flowWorkspace, flowTrans, ggplot2, ggridges, reshape2, rlist, stringr, Rlist, RphenoGraph, Rtsne and umap


WORKFLOW : ---- This workflow is desgined for transforming aligning and clustering multiple flowcytometry data (.fcs) ----


-Import/install packages
    -some are probably missing, it will be patched.
    
-Reads in the data

-Subsets

-Transform the data (3 transformations available: choose the biexp chunck for comparing multiple datasets, the others allows experimented R users to analyse each file separately)
    -show a multiple densityplot that represents the data distribution
    
-Alignment step (critical, probably needs user adjustment: chunck "Alignment")
    -show 4 multiple densityplots: 1) raw data, 2) biexp transformed, 3) aligned and the retrotransformed(after alignment)

-t-sne representations
    -sample and markers intensities.

-clustering
    -Phenograph & flowSOM available
    -get informations about the clustering

-Associate clustering to a cell type - Necessarely biased
    - Manual association : User give manually which cluster corresponds to which cell type by manually interpreting the values.
    - Establish a median correlation score between ce
    
-Manual association
    -visualize given informationsÂ§
    -perform correlation cell by cell (with required normalization methods)
    
-Train a randomForest classifier


##Import the required libraries

This chunck import the data. (Here is a particular example only area channels were available in one of the file. This example besides shows how to concatenate). 
```{r,include=FALSE}
require("flowCore")
require("flowWorkspace")
require("flowTrans")
require("ggplot2")
require("ggridges")
require("stringr")
require("rlist")
require("scales")
require("reshape2")
require("Rtsne")
require("umap")
require("wadeTools")
require("flowStats")
require("gridExtra")
require("scales")

# for clustering we use Rphenograph which needs to be installed directly from the github of JinmiaoChen Lab
if(!require(devtools)){
  install.packages("devtools") # If not already installed
}
devtools::install_github("JinmiaoChenLab/Rphenograph")

require("Rphenograph")
source("basic_functions.R")
source("/home/rhalena/Desktop/GITHUB/FACS-data-analysis/basic_functions.R")

```

##Read the data
```{r,include=FALSE}

# clear workspace
rm(list = ls())

#Set the path of the data folder
# Alex
data_path="/home/alx/Documents/McGill_Neuro/Datasets/FACS_Paper/FIG2"
#Rhalena
data_path="/home/rhalena/Documents/Documents/MyPapers/FACS/FCS files for bioinfo analysis/2020-04-20" 

# set the path to where you would like to save outputs
save_path = "/home/rhalena/Desktop/GITHUB/FACS-data-analysis/output/"

#make a flowset object
exp=read.flowSet(path=data_path,transformation =FALSE ,emptyValue = FALSE,package="flowWorkspace")
# emptyValue = False doesn't consider empty rows

#select compensated channels, FCS and SSC that finishes by A (indicating the aea value) using regular expression
exp=fsApply(exp,function(x){x[ ,grepl("^[{'FJComp'}|{'FCS'}|{'SSC'}].*A$",colnames(exp))]})
#Still a flowset (fsApply -> apply a function to a flowset)


# if the data is located in a different space or you don't have the same type of fcs file exported (not complete) 
# don't run if the data is all the same folder and has all measures
# 
# data_path="/home/alx/Documents/McGill_Neuro/Datasets/FACS_Paper/FIG2"
# exp1=read.flowSet(path=data_path,transformation =FALSE ,emptyValue = FALSE,package="flowWorkspace")
# exp1=fsApply(exp1,function(x){x[ ,grepl("^[{'FJComp'}|{'FCS'}|{'SSC'}].*A$",colnames(exp1))]})#SELECT COMPENSED CHANNELS AND AEA VALUES
# exp=rbind2(exp,exp1) #FlowSet object
```

##Subsetting

These chuncks allows you to subset the data. It is usefull for scaling experiments or lighten the data. 
User have to set the "desired_size" value and run the last chunck
```{r,include=FALSE}
desired_size=1500
```

This chunck allows you to set the subsampling size to the number of cells in the smallest sample
```{r,include=FALSE}
desired_size=min(fsApply(exp,function(x){nrow(x@exprs)}))
```

Subsets the data
```{r,echo=FALSE}
set.seed(42) #Set a seed for reproducibility 
sf=sampleFilter(filterId = "SizeFilter", size =desired_size)#establish a "filter" to subset
exp=fsApply(exp,function(x){Subset(x,sf)})#apply the filter
```

check files names
```{r}
sampleNames(exp)
```

Rename the files (optional)
```{r}
sampleNames(exp)<-c("3450c2","AIW2","AJG2","3450c1","3450c3","AIW1","AIW3","AJG1","AJG3")
sampleNames(exp)
```
+++++ ADD RENAME MARKERS WITH INPUT +++++++

still to be added

##Transformation Step (Key step)
Just choose one

1. Biexponential: This one allows the biexp transformation (that suits best for comparing multiple datasets)

```{r,echo=FALSE}
biexp  <- biexponentialTransform("myTransform")
expbe <- transform(exp, transformList(colnames(exp), biexp))
```

2. Arcsinh:  This one allows to transform with optimized parameters or arcsinh transform. The parameters are based on maximum likelyhood assuming a normal distribution (it suits best the clustering of each file separately, lit.)
```{r,echo=FALSE}
expmas=fsApply(exp, function(x){flowTrans(x,"mclMultivArcSinh"
                                       ,colnames(x)[vapply(colnames(x), function(y) all(grepl("^[{'FJComp'}|{'FCS'}|{'SSC'}].*A$", y)),logical(1))]
                                       ,n2f = FALSE,
                                       parameters.only = FALSE)$result} )
```

3. What is this called? Can you change from the default parameters?

This one (with default parameters) is sensibly the same as biexp with default parameters. Those transformations gives equivalent results on clustering or manual gating
```{r,echo=FALSE}
asinh=arcsinhTransform(transformationId="defaultArcsinhTransform", a=1, b=1, c=0)
expasinh=transform(exp, transformList(colnames(exp), asinh))
```

Call densityplots of two flowsets
```{r}
# see plots
plotdensity_flowset(rename_markers(exp))
plotdensity_flowset(rename_markers(expbe))

# save plot
png(file="densityplot_expbe_rename.png",width=900*1.618,height=700)
plotdensity_flowset(rename_markers(expbe))
dev.off()
```

Now that the data is transformed, the intensities are distributed in an interpretable way. We can begin the alignment.




This gives an insight on the markers and their associated column in each .fcs file. Be carefull : the non consistency of marker names can lead to errors in the following steps. (visualize the caracteristic values of intensities per clusters)
```{r}
getmarkersinfo(rename_markers(exp))
```
##Alignment

This chunck perform the alignment of the densitypeaks. It requires 2 calls of the function depending on the shape of the distribution. The plotting allows to be sure that the alignment performed well. If not, rerun the chunck by changing the peak.density.thr and the associated columns (2nd arg) for the alignment with 1 peak and for the alignment with 2 peaks.
```{r}
normtr=gaussNorm(expbe,colnames(expbe)[c(3,5:6,9:length(colnames(exp)))],max.lms = 2,peak.density.thr = 0.01)
expbe_norm2=normtr$flowset

normtr=gaussNorm(expbe_norm2,colnames(expbe_norm2)[c(4,7:8)],max.lms = 1,peak.density.thr = 0.05)
expbe_al=normtr$flowset

#exp_al=fsApply(expbe_al,function(x){inv.biexp(x,params=colnames(x))})#Apply the retrotransformation. Require "wadetools" package

#png(file="/home/alx/Documents/McGill_Neuro/Scripts/FACS_clustering/densityplot_expbe_rename.png",width=900*1.618,height=700)
# we need titles on these plots
dp_expbe <- plotdensity_flowset(rename_markers(expbe))
dp_expbe_al <- plotdensity_flowset(rename_markers(expbe_al))
dp_expbe
dp_expbe_al

# save_path was deffined in chunk at the begining of the notebook
file_name = paste(save_path,"density_plots_expbe_pre_post_alignment.png",sep="")
# better to have these plots in a grid but they look weird like that.  We should put only one legend on the side
png(file=file_name, width=900*1.618,height=700)
grid.arrange(dp_expbe, dp_expbe_al, nrow = 1) 
dev.off()


```



This chunck allows to perform and plot a tsne with all usual parameters.

Warning: colstoignore corresponds to the markers to ignore. (Usually get rid of the LiveDead marker and size markers (FSC SSC - respectively 1 and 2) - debatable). If you don't know the corresponding columns, you can access the marker names by calling the flowCore function 'markernames(flowset)' (remember that FSC and SSC are not considered as markers and do not appears in the list) or 'getmarkersinfo(flowset)' for more informations

```{r}
tsne_expbe=tsne_flowset(expbe_al,scale=TRUE,colstoignore = c(1,2,9) ,dims = 2, perplexity=150,theta=0.5, verbose=FALSE, max_iter = 1000,eta=300)
sample=getsample(expbe_al)

plot_tsne(tsne_expbe,"tsne")
#saveRDS(tsne_expbe,file="/home/alx/Documents/McGill_Neuro/Scripts/FACS_clustering/REFERENCE_TSNE_1578_expbe_col9.RData")
object_name = paste(save_path,"Aug7_2020_" ,"tSNE_expbe_9col_1500_cells.Rdata",sep="")
saveRDS(tsne_expbe,object_name)

# load a previously saved object -- enter the filepath and file name RData file
#tsne_expbe <- load(object_name)

# think about a saving argument in this function so that you can set it to TRUE, give a pathway or leave it as working directory and each file is saved, maybe a file prefix can be added as well
plot_marker_tsne(expbe_al,tsne_expbe,c(1,2,9))


```

If you prefer umap, it has to be adapted for more figures. 
```{r}
umap_expbe=umap_flowset(expbe_al,colstoignore=c(9),scale=TRUE)
plot_umap(umap_expbe,"hasar")
```

------- Just for "fun", a 3D tsne ---------
```{r}
# this should be taken out or changed to the flow data

library(car)
library(rgl)
tsne_expbe30=tsne_flowset(expbe_al,scale=TRUE,colstoignore = c(9) ,dims = 3, perplexity=30,theta=0.5, verbose=FALSE, max_iter = 1000,eta=500)
colors=c("deepskyblue1","orange","violetred2","maroon2","brown2","dodgerblue","cyan","yellow3","darkgoldenrod2","brown3","maroon2","violetred2")
expcounts=fsApply(exp,function(x){nrow(x)})
cols3d=c()
for (i in 1:length(expcounts)){
  cols3d=append(cols3d, rep(colors[i],expcounts[i]))
}
scatter3d(x=tsne_expbe30$Y[,1],y=tsne_expbe30$Y[,2],z=tsne_expbe30$Y[,3],point.col=cols3d,surface=FALSE)
```
----------------------------------------

Clustering

This chunck performs the Phenograph clustering and save the results in a variable. Another chunck will read this variable to get informations about the clustering results.
Rphenograph_flowset(flowet,columns to ignore, k, scale (boolean)). Based on litterature, golden standard is to not consider FSC and SSC channels, nor the Live - Dead channel (if present). K corresponds to the initial K-NN graph computed by the phenograph method. Lower values of k yield a greater number of groups.

```{r}
# this function will take a long time to run. The computation lenght increases with cell number

pheno_expbe_al=Rphenograph_flowset(expbe_al,colstoignore=c(1,2,9),k=250,scale=TRUE) #Apply the function

# save the clustered object
object_name = paste(save_path,"Aug7_2020_" ,"pheno_expbe_al_expbe_9col_1500_cells.Rdata",sep="")
saveRDS(pheno_expbe_al,object_name)

```

This chunck performs the flowSOM clustering (faster) and save the results in a variable. Another chunck will read this variable to get informations about the clustering results. You can have more informations about the parameters by typing "?FlowSOM" in the R console.  You can define a number of clusters by adding "nClus" in the parameters of the FlowSOM function
```{r}
library(FlowSOM)
flowSOM.clustering=GetMetaclusters(FlowSOM(expbe_al,pattern=".fcs",transform=FALSE, compensate = FALSE, spillover = NULL,colsToUse =  c(3:8,10:16),maxMeta = 30,nClus = 25 ))

plot_tsne_clust(tsne_expbe,flowSOM.clustering,"flowSOM clustering result")
```


This chunck will compute differential expression
```{r}
```



This chunck provides a plots and information about the clustering (number of cells per sample per cluster and mean values)
```{r}
sample_per_cluster(pheno_expbe_al[[2]]$membership)
mean_per_cluster(rename_markers(expbe_al),pheno_expbe_al[[2]]$membership,colstoignore = c(9))

#png(file="/home/alx/Documents/McGill_Neuro/Scripts/FACS_clustering/phenograph_retroexp_scaled_clusters_redim.png",width=1000*1.618,height=1000)
plot_tsne_clust(tsne_expbe, pheno_expbe_al[[2]]$membership,"Phenograph clustering (k=350) of biexp transformed aligned scaled values of 9 MBOs with 1578 cells each")
#dev.off()
heatmap_cluster(rename_markers(expbe_al),pheno_expbe_al[[2]]$membership,c(1,2,9))
```

do.call("grid.arrange", c(myplots, ncol=nCol))


#To assign these clusters to cell profiles automatically use the following chunck. User need to import an expected expression table by phenotype
```{r}
norm_cellpheno=read.csv(file="/home/alx/Documents/McGill_Neuro/Datasets/FACS_Paper/ExpessionCellPhenotypeTable3.csv")

cluster_correlation_by_cell=correlation_cluster_celltype(expbe_al,membership(pheno_expbe_al[[2]]),norm_cellpheno,c(1,2,9))

summary_correlation_by_cluster=lapply(cluster_correlation_by_cell,function(x){apply(x,2,summary)})

assigned_celltype=lapply(summary_correlation_by_cluster,function(x){names(which.max(x["Median",]))})


mccb=melt(cluster_correlation_by_cell)
colnames(mccb)<-c("cell","phenotype","Pearson_correlation_score","cluster")
ggplot(mccb,aes(x=as.factor(cell),y=as.factor(phenotype),fill=Pearson_correlation_score))+geom_raster(size=0.5)+  scale_fill_gradient2(low="cyan2", high ="darkorchid3")+scale_x_discrete(position = "top")+facet_grid(~cluster,scale="free",drop=TRUE)
```
This chunck gives several insight on the association of clusters
```{r}
summary_correlation_by_cluster
assigned_celltype
```

#The two following chuncks allows the user to define its own association. 
The first one give the order of the clusters to rename & the second one takes the user input and creates the association.
```{r}
unique(pheno_expbe_al[[2]]$membership)
```

```{r}
user_celltypes<-c("Neuron","Treize","Six","Huit","Cinq","Quinze","Quatorze","Trois","Onze","Sept","Deux","Neuf","Seize","Quatre","Un")

assigned_celltype=NULL
assigned_celltype[paste0("cluster_",unique(pheno_expbe_al[[2]]$membership))]=user_celltypes
```

This chunck creates the list of assignigned cell type of each cell that will eventually be used by the classifier.
```{r}
list_of_celltypes=as.vector(assigned_celltype[paste0("cluster_",pheno_expbe_al[[2]]$membership)])
```

##RandomForest classifier
This chunck extract the values to use for the classifier and associates the previous "list_of_celltypes". We strongly recommand to get rid of the same columns
```{r}
library(randomForest)

facsdata=list.rbind(lapply(as.list(rename_markers(expbe_al)@frames),function(x){x=as.data.frame(x@exprs[,-c(1,2,9)])}))
facsdata$assigned_celltype<-as.factor(as.character(list_of_celltypes))
```

#This chunck train a randomForest classifier with all the data
```{r}
rf_classifier_model<-randomForest(assigned_celltype~ . , data=facsdata,proximity=TRUE,ntree=250)
rf_classifier_model
importance(rf_classifier_model)
```


To predict, here's the same example with the same dataset divided in training and test dataset
```{r}
#Separate the data in 2 groups with 70% of training data
set.seed(42)
ind = sample(2, nrow(facsdata), replace=TRUE, prob=c(0.7,0.3))
trainData = facsdata[ind==1,]
testData = facsdata[ind==2,]

#Train the model with training data
rf_classifier_model = randomForest(assigned_celltype~ . , data=trainData, ntree=100, proximity=T)

#Prediction with training data
table(predict(rf_classifier_model), trainData$assigned_celltype)


testData$assigned_celltype<-NA
#Prediction with test data
predicted_pheno = predict(rf_classifier_model, newdata=testData)
confusion_matrix=table(irisPred, testData$assigned_celltype)
```


```{r}
oob.err.data=data.frame(Trees=rep(1:nrow(rf_classifier_model$err.rate),times=ncol(rf_classifier_model$err.rate)),
                        Type=rep(c(colnames(rf_classifier_model$err.rate)),each=nrow(rf_classifier_model$err.rate)),
                        Error=as.vector(apply(rf_classifier_model$err.rate,2,function(x){x})))

ggplot(oob.err.data,aes(x=Trees,y=Error))+geom_line(aes(color=Type))+theme_minimal()
```

-----MANUAL ASSIGNATION-----

Read and compare zscore-normalized values of expected cell types to the zscore-normalized values of each cell

This chunck load and represents with a heatmap the given expected values for different phenotypes. We expect these values being between 0 and 1

```{r}
norm_cellpheno=read.csv(file="/home/alx/Documents/McGill_Neuro/Datasets/FACS_Paper/ExpessionCellPhenotypeTable3.csv")

cellpheno=norm_cellpheno[,c(2:ncol(norm_cellpheno))]
cellpheno$X=as.factor(cellpheno$X)
mlt_cellpheno=melt(cellpheno)
colnames(mlt_cellpheno)<-c("marker","phenotype","value")
#png(file="/home/alx/Documents/McGill_Neuro/Scripts/FACS_clustering/phenotype_heatmap",width=400*1.618,height=400)
ggplot(mlt_cellpheno,aes(x=phenotype,y=marker,fill=value))+geom_tile(size=0.5)+  scale_fill_gradient2(mid="steelblue2", high ="maroon2",breaks=c(0.2,0.8),labels=c("Low","High"), na.value = "grey50")+scale_x_discrete(position = "top")
#dev.off()
```

This chunck defines and apply the "rename_channels" function which replaces the laser names by their associated marker. Please note that here the script use expbe_al, corresponding to the biexponential transformed aligned values, but you can use another data or transformations.
```{r}

rename_expbe_al=rename_markers(expbe_al)
facsdata=lapply(as.list(rename_expbe_al@frames),function(x){x=as.data.frame(x@exprs[,-c(1,2,9)])})
binded_facs_data=list.rbind(facsdata)

binded_expr=as.data.frame(scale(as.matrix(binded_facs_data),scale=TRUE,center=TRUE))

binded_expr=as.data.frame(apply(binded_expr,2, minmax_normalize))

norm_cellpheno[is.na(norm_cellpheno)]=0

rownames(norm_cellpheno)=toupper(norm_cellpheno$X)
colnames(binded_expr)=toupper(colnames(binded_expr))

intersect_markers=intersect(colnames(binded_expr),rownames(norm_cellpheno))
intersect_markers=intersect_markers[order(intersect_markers)]

norm_cellpheno=norm_cellpheno[intersect_markers,]
binded_expr=binded_expr[,intersect_markers]

corlist=t(apply(as.data.frame(binded_expr),1, assigntype, norm_cellpheno))

colnames(corlist)=colnames(norm_cellpheno[,3:ncol(norm_cellpheno)])

assignation=apply(corlist,1,function(x){
  max=max(x)
  if (max!=abs(max)){
    return("Unassigned")
  }
  else{
    return(colnames(corlist)[which.max(x)])
  }
})

values=list()
values$correlation=apply(corlist,1,function(x){max(x)})
values$assignation=assignation
values=as.data.frame(values)
values$assignation=as.factor(values$assignation)


data_summary <- function(x) {
   m <- mean(x)
   ymin <- m-sd(x)
   ymax <- m+sd(x)
   return(c(y=m,ymin=ymin,ymax=ymax))
}

ggplot(values,aes(x=assignation,y=correlation,color=assignation))+geom_violin(trim = FALSE) + stat_summary(fun.data=data_summary)+scale_color_manual(values = c("#36dee6", # bright blue
            "#6d71d8", # blue
            "#5c3788", # dark purple blue 
            "#b1457b", # purple
            "#ca73c6", # other purple
            "#006400", # dark green
            "#54b06c", # green
            "#799e43", # olive green
            "#c1a339", # yellow mustard
            "#b86738", # orange
            "Khaki3", 
            "brown3",
            "darkgrey"))


tohm=cbind(as.data.frame(list.rbind(lapply(as.list(expbe_al@frames),function(x){x@exprs[,-c(1,2,9)]}))),as.factor(assignation))
tohm=tohm[order(tohm$`as.factor(assignation)`),]
tohm$cell=as.factor(c(1:nrow(tohm)))
totohm=as.data.frame(melt(tohm))
colnames(totohm)<-c("cluster","cell","marker","value")
totohm=totohm[order(totohm$cluster),]


ggplot(as.data.frame(assignation),aes(assignation,fill=assignation))+geom_histogram(stat="count")+scale_fill_manual(values = c("#36dee6", # bright blue
            "#6d71d8", # blue
            "#5c3788", # dark purple blue 
            "#b1457b", # purple
            "#ca73c6", # other purple
            "#006400", # dark green
            "#54b06c", # green
            "#799e43", # olive green
            "#c1a339", # yellow mustard
            "#b86738", # orange
            "Khaki3", 
            "brown3",
            "darkgrey"))
```

SOME PLOTS
assignment=assignation

ggplot(as.data.frame(tsne_expbe$Y)) + geom_point(aes(x=tsne_expbe$Y[,1], y=tsne_expbe$Y[,2],col=sample),size=0.5)+ guides(colour = guide_legend(override.aes = list(size=3)))+ scale_colour_manual(values  = c("#36dee6", # bright blue
            "#6d71d8", # blue
            "#5c3788", # dark purple blue 
            "#b1457b", # purple
            "#ca73c6", # other purple
            "#006400", # dark green
            "#54b06c", # green
            "#799e43", # olive green
            "#c1a339", # yellow mustard
            "#b86738", 
            "red"))+ggtitle("t-sne 9 organoids with 1578 cells each")

ggplot(as.data.frame(tsne_expbe$Y)) + geom_point(aes(x=tsne_expbe$Y[,1], y=tsne_expbe$Y[,2],col=as.factor(membership(pheno_expbe_al[[2]]))),size=0.5)+ guides(colour = guide_legend(override.aes = list(size=3)))+ scale_colour_manual(values  = c("#36dee6", # bright blue
            "#6d71d8", # blue
            "#5c3788", # dark purple blue 
            "#b1457b", # purple
            "#ca73c6", # other purple
            "#006400", # dark green
            "#54b06c", # green
            "#799e43", # olive green
            "#c1a339", # yellow mustard
            "#b86738" ,"darkorchid3","chocolate","chartreuse3","bisque3","aquamarine2","mediumspringgreen","peru","peachpuff4","yellowgreen","thistle2","olivedrab1","powderblue","rosybrown1","rosybrown3","lawngreen","mistyrose","gold4",
            "red"))+ggtitle("t-sne 9 organoids with 1578 cells each")


ggplot(values,aes(x=assignment,y=correlation,color=assignment))+geom_violin(trim = FALSE) + stat_summary(fun.data=data_summary)+scale_color_manual(values = c("#36dee6", # bright blue
            "#6d71d8", # blue
            "#5c3788", # dark purple blue 
            "#b1457b", # purple
            "#ca73c6", # other purple
            "#006400", # dark green
            "#54b06c", # green
            "#799e43", # olive green
            "#c1a339", # yellow mustard
            "#b86738", # orange
            "Khaki3", 
            "brown3",
            "darkgrey"))+ggtitle("Pearson correlation score")

ggplot(totohm,aes(x=cell,y=marker,fill=value))+geom_raster(size=0.5)+  scale_fill_gradient2(low="cyan2", high ="darkorchid3")+scale_x_discrete(labels=totohm$cluster,position = "top")+theme(axis.text.x = element_blank())+facet_grid(~cluster,scales="free",drop=TRUE)+ggtitle("biexponential transformed aligned values of assigned cells")

ggplot(as.data.frame(assignment),aes(assignment,fill=assignment))+geom_histogram(stat="count")+scale_fill_manual(values = c("#36dee6", # bright blue
            "#6d71d8", # blue
            "#5c3788", # dark purple blue 
            "#b1457b", # purple
            "#ca73c6", # other purple
            "#006400", # dark green
            "#54b06c", # green
            "#799e43", # olive green
            "#c1a339", # yellow mustard
            "#b86738", # orange
            "Khaki3", 
            "brown3",
            "darkgrey"))
            
```{r}
comp2max<-function(corvalues){
  truemax=corvalues[which.max(corvalues)]
  intervalue=corvalues[-which.max(corvalues)]
  secondmax=intervalue[which.max(intervalue)]
  return(truemax-secondmax)
}

maxdiff=apply(corlist, 1,comp2max)
getmean=apply(corlist,1,function(x){mean(x)})
res=maxdiff-getmean

getmax=apply(corlist,1,function(x){max(x)})
```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
